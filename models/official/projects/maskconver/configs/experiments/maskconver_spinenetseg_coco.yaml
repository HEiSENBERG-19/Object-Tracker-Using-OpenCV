# Train on 4x8 TPU and eval on GPU.
# http://tb/6152990635147738742 - PQ 47.
# Note: Above tensorboard has the best number, but using a different config compared to this file.
runtime:
  distribution_strategy: 'tpu'
  mixed_precision_dtype: 'float32'
task:
  init_checkpoint: 'spinenetseg/28194596/ema_checkpoints'
  init_checkpoint_modules: ['backbone']
  losses:
    l2_weight_decay: 0.00001
    mask_weight: 10.0
  model:
    input_size: [640, 640, 3]
    embedding_size: 256
    padded_output_size: [640, 640]
    norm_activation:
      activation: 'swish'
      norm_epsilon: 0.001
      norm_momentum: 0.99
      use_sync_bn: true
    backbone:
      type: 'spinenet_seg'
      spinenet_seg:
        model_id: '49'
        stochastic_depth_drop_rate: 0.0
    decoder:
      aspp:
        level: 3
        pool_kernel_size: null
        dilation_rates: [12, 24, 36]
      type: aspp
    class_head:
      level: 3
      num_convs: 2
      feature_fusion: 'deeplabv3'
      prediction_kernel_size: 3
      use_depthwise_convolution: false
      upsample_factor: 1
    per_pixel_embedding_head:
      level: 3
      num_convs: 2
      feature_fusion: 'deeplabv3'
      prediction_kernel_size: 3
      use_depthwise_convolution: false
      upsample_factor: 1
    mask_embedding_head:
      level: 3
      num_convs: 2
      feature_fusion: 'deeplabv3'
      prediction_kernel_size: 3
      use_depthwise_convolution: false
      upsample_factor: 1
    panoptic_generator:
      object_mask_threshold: 0.2
  train_data:
    global_batch_size: 64
    parser:
      gaussaian_iou: 0.6
trainer:
  optimizer_config:
    learning_rate:
      cosine:
        decay_steps: 200000
        initial_learning_rate: 0.08
      type: cosine
    optimizer:
      sgd:
        momentum: 0.9
      type: sgd
    warmup:
      linear:
        name: linear
        warmup_learning_rate: 0
        warmup_steps: 2000
      type: linear
  train_steps: 200000
  steps_per_loop: 100
  validation_interval: 1000
  checkpoint_interval: 1000
  summary_interval: 1000
