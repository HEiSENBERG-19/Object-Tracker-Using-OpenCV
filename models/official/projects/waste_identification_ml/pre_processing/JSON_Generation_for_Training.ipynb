{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JmF5ohLbPlF"
      },
      "source": [
        "# Pre processing steps of a COCO JSON annotated file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXwwz3PlbUX2"
      },
      "source": [
        "Given a single COCO annotated JSON file, your goal is to pre-process in order to remove noise and manipulate it into a form which is suitable for training a ML model. This script will also check if the annotated images are broken or missing.The output of this notebook should be 2 JSON annotation files -\n",
        "`Material and its sub type (e.g Plastics_HDPE)` and `'Material form and its sub type (e.g.Paper-Products-White-Paper)'`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1SxGZD2bv8E"
      },
      "source": [
        "The COCO annotation file includes the following -\n",
        "\n",
        "1. Name of the images.\n",
        "\n",
        "2. Dimensions of the images.\n",
        "\n",
        "3. Classes in the image category.\n",
        "\n",
        "4. Name of the super categories of the classes.\n",
        "\n",
        "5. Area acquired by the segmented pixels in an image.\n",
        "\n",
        "6. Bounding box co-ordinates.\n",
        "\n",
        "7. Annotated segmentation coordinates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0v31gxTbweO"
      },
      "source": [
        "There is a lot of noise in the real world annotation file. The images name could be wrong. The images mentioned in an annotation file may not be present in the image folder, which will disrupt the model training procedure. The contents within an annotation file may not match with each other. Even the files present in an image folder may be broken or truncated, which will cause errors while reading image files. Our goal is to eradicate all these problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyFn96EKb7A-"
      },
      "source": [
        "Our goal is to make sure that all information in the key values corresponds to each other correctly. This notebook will help you achieve this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6aXxxox0DDa"
      },
      "source": [
        "## Import labels and sample JSON file\n",
        "To import total classes for the material, material_form and plastic_type we will import the label files from the waste_identification_ml project from Tensorflow Model Garden.\n",
        "We will also import a noisy sample JSON file to illustrate an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WluEHMZYm0zM",
        "outputId": "7bdc802d-4b11-4959-8255-64099ff530a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3862  100  3862    0     0  18499      0 --:--:-- --:--:-- --:--:-- 18567\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2427  100  2427    0     0   8695      0 --:--:-- --:--:-- --:--:--  8667\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   264  100   264    0     0    935      0 --:--:-- --:--:-- --:--:--   936\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   422  100   422    0     0   1525      0 --:--:-- --:--:-- --:--:--  1528\n",
            "mkdir: cannot create directory ‘image_folder’: File exists\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 3303k  100 3303k    0     0  4518k      0 --:--:-- --:--:-- --:--:-- 4518k\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "curl -O \"https://raw.githubusercontent.com/tensorflow/models/master/official/\"\\\n",
        "\"projects/waste_identification_ml/two_model_inference/labels.py\"\n",
        "\n",
        "curl -O \"https://raw.githubusercontent.com/tensorflow/models/master/official/\"\\\n",
        "\"projects/waste_identification_ml/pre_processing/config/sample_json/dataset.json\"\n",
        "\n",
        "\n",
        "curl -O \"https://raw.githubusercontent.com/tensorflow/models/master/official/\"\\\n",
        "\"projects/waste_identification_ml/pre_processing/config/data/\"\\\n",
        "\"two_model_strategy_material.csv\"\n",
        "\n",
        "curl -O \"https://raw.githubusercontent.com/tensorflow/models/master/official/\"\\\n",
        "\"projects/waste_identification_ml/pre_processing/config/data/\"\\\n",
        "\"two_model_strategy_material_form.csv\"\n",
        "\n",
        "mkdir image_folder\n",
        "\n",
        "curl -o image_folder/image_2.png \"https://raw.githubusercontent.com/\"\\\n",
        "\"tensorflow/models/master/official/projects/waste_identification_ml/\"\\\n",
        "\"pre_processing/config/sample_images/image_2.png\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRhCAFlVcRm0"
      },
      "source": [
        "## Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnxbo8GBcN2O"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import tqdm\n",
        "import json\n",
        "from PIL import Image\n",
        "import subprocess\n",
        "import copy\n",
        "import os\n",
        "from google.colab import files\n",
        "from labels import load_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGOCdeiucUgq"
      },
      "outputs": [],
      "source": [
        "# @title Utility Functions { display-mode: \"form\", run: \"auto\" }\n",
        "def read_json(file):\n",
        "  \"\"\"Read any JSON file.\n",
        "\n",
        "  Args:\n",
        "    file: path to the file\n",
        "  \"\"\"\n",
        "  with open(file) as json_file:\n",
        "    data = json.load(json_file)\n",
        "  return data\n",
        "\n",
        "\n",
        "def search_dict_value(dic, id):\n",
        "  \"\"\"Returns the key of the dictionary from its value'\n",
        "\n",
        "  Args:\n",
        "    dic = Mapping to search by value.\n",
        "    id = Value to search.\n",
        "  \"\"\"\n",
        "  key_list = list(dic.keys())\n",
        "  val_list = list(dic.values())\n",
        "  position = val_list.index(id)\n",
        "  return key_list[position]\n",
        "\n",
        "\n",
        "def delete_truncated_images(folder_path: str) -\u003e None:\n",
        "  \"\"\"Find and delete truncated images.\n",
        "\n",
        "  Args:\n",
        "    folder_path: path to the folder where images are saved.\n",
        "  \"\"\"\n",
        "  # path to the images folder to read its content\n",
        "  files = glob.glob(folder_path + '/*')\n",
        "  print('Total number of files in the folder:', len(files))\n",
        "\n",
        "  num = 0\n",
        "\n",
        "  # read all image files and remove them from the directory in case they are broken\n",
        "  for file in tqdm.tqdm(files):\n",
        "    if file.endswith(('.png','.jpg')):\n",
        "      try:\n",
        "        img = Image.open(file)\n",
        "        img.verify()\n",
        "      except:\n",
        "        num = num + 1\n",
        "        subprocess.run(['rm', file])\n",
        "        print('Broken file name:  ' + file)\n",
        "  if num == 0:\n",
        "    print('\\nNo broken images found')\n",
        "  else:\n",
        "    print('Total number of broken images found:', num)\n",
        "\n",
        "\n",
        "def spelling_correction(dic, typo_dict):\n",
        "  \"\"\"Correcting some common spelling mistakes.\"\"\"\n",
        "  for i in dic['categories']:\n",
        "    for old, new in typo_dict.items():\n",
        "      i['name'] = i['name'].replace(old, new)\n",
        "  return dic\n",
        "\n",
        "\n",
        "def labeling_correction(dic, labels_dict, num):\n",
        "  \"\"\"Matching annotated labels with the correct labels.\n",
        "\n",
        "  Mapping the modified labeling ID with the corresponding original ID for alignment\n",
        "  of categories.\n",
        "\n",
        "  Args:\n",
        "    dic: JSON file read as a dictionary\n",
        "    num: keyword position inside the label\n",
        "    labels_dict: dictionary showing the labels ID of the original categories\n",
        "  \"\"\"\n",
        "  mapping_list = []\n",
        "  incorrect_labels = []\n",
        "\n",
        "  for i in dic['categories']:\n",
        "      sp = i['name'].split('_')\n",
        "\n",
        "      if num == 1:\n",
        "          target_value = sp[0].lower() + '_' + sp[1].lower()\n",
        "      elif num == 4:\n",
        "          target_value = sp[4].lower()\n",
        "      else:\n",
        "          raise ValueError(\"Invalid value for 'num'\")\n",
        "\n",
        "      if target_value in labels_dict.values():\n",
        "          id_match = search_dict_value(labels_dict, target_value)\n",
        "          mapping_list.append((i['id'], target_value, id_match))\n",
        "      else:\n",
        "          incorrect_labels.append(i['id'])\n",
        "\n",
        "  return mapping_list, incorrect_labels\n",
        "\n",
        "\n",
        "def images_key(dic):\n",
        "  \"\"\"Align the data within the dictionary in the 'images' key.\n",
        "\n",
        "  The 'image_id' parameter in the 'annotation' key is the same as 'id' in the 'images' key of the dictionary. This function\n",
        "  will also remove all image data from the 'images' key whose 'id' does not\n",
        "  match with 'image_id' in the 'annotation' key in the dictionary.\n",
        "\n",
        "  Args:\n",
        "    dic: where the JSON file is read into\n",
        "  \"\"\"\n",
        "  image_ids = set(i['image_id'] for i in dic['annotations'])\n",
        "  new_images = [i for i in dic['images'] if i['id'] in image_ids]\n",
        "  return new_images\n",
        "\n",
        "\n",
        "def annotations_key(dic, incorrect_labels, mapping_dict):\n",
        "  \"\"\"Align the data within the dictionary  in the 'annotation' key.\n",
        "\n",
        "  Notice that the 'category_id' in the 'annotation' key is same as 'id'\n",
        "  in the 'categories' key of the dictionary.\n",
        "\n",
        "  Args:\n",
        "    dic: where the JSON file is read into\n",
        "  \"\"\"\n",
        "  new_annotation = []\n",
        "\n",
        "  for i in dic['annotations']:\n",
        "    id = i['category_id']\n",
        "    if (id not in incorrect_labels) and (id in [tup[0] for tup in mapping_dict]):\n",
        "      new_id = [i[2] for i in mapping_dict if i[0] == id][0]\n",
        "      i['category_id'] = new_id\n",
        "      new_annotation.append(i)\n",
        "  return new_annotation\n",
        "\n",
        "\n",
        "def annotated_images(folder_path, dic):\n",
        "  \"\"\"Get images infromation that are mentioned in an annotation file but are not present in an image folder.\n",
        "\n",
        "  Args:\n",
        "    folder_path: path of an image folder.\n",
        "  \"\"\"\n",
        "  # read the file names from the directory\n",
        "  files = glob.glob(folder_path + '/*')\n",
        "  files = set(map(os.path.basename, files))\n",
        "\n",
        "  # list of images in an annotation file\n",
        "  dic['images'] = [i for i in dic['images'] if i['file_name'] in files]\n",
        "  return dic\n",
        "\n",
        "\n",
        "def image_annotation_key(dic):\n",
        "  \"\"\"Check if same images are present in both \"images\" key and \"annotations\" key.\n",
        "\n",
        "  List of the image IDs which are in the \"images\" key but NOT in \"annotation\" key.\n",
        "  Remove information if they are not present in both keys.\n",
        "\n",
        "  Args:\n",
        "    dic: annotation file read as a dictionary\n",
        "  \"\"\"\n",
        "  images_id = [i['id'] for i in dic['images']]\n",
        "  annotation_id = [i['image_id'] for i in dic['annotations']]\n",
        "  common_list = set(images_id).intersection(annotation_id)\n",
        "  dic['images'] = [i for i in dic['images'] if i['id'] in common_list]\n",
        "  dic['annotations'] = [i for i in dic['annotations'] if i['image_id'] in common_list]\n",
        "  return dic\n",
        "\n",
        "\n",
        "def categories_dictionary(list_of_objects):\n",
        "  \"\"\"Generates a list of dictionaries representing categories of objects.\n",
        "\n",
        "  Each dictionary has an 'id' corresponding to its order in the list, a 'name'\n",
        "  taken from the input list, and a fixed 'supercategory' set as 'objects'.\n",
        "\n",
        "  Args:\n",
        "      list_of_objects: List of object names to be used as categories.\n",
        "\n",
        "  Returns:\n",
        "      list: List of dictionaries, each representing a category.\n",
        "\n",
        "  Example:\n",
        "      \u003e\u003e\u003e categories_dictionary(['car', 'bus'])\n",
        "      [{'id': 1, 'name': 'car', 'supercategory': 'objects'},\n",
        "        {'id': 2, 'name': 'bus', 'supercategory': 'objects'}]\n",
        "  \"\"\"\n",
        "  objects_dictionaries = []\n",
        "  for num, m in enumerate(list_of_objects, start=1):\n",
        "    objects_dictionaries.append({\n",
        "        'id': num,\n",
        "        'name': m,\n",
        "        'supercategory': 'objects'\n",
        "    })\n",
        "\n",
        "  return objects_dictionaries\n",
        "\n",
        "\n",
        "def print_incorrect_labels(incorrect_labels, data_postprocessing, m):\n",
        "    \"\"\"Prints the incorrect labels and their count.\n",
        "\n",
        "    Args:\n",
        "        incorrect_labels: List of incorrect label IDs.\n",
        "        data_postprocessing: The data containing postprocessing details.\n",
        "        m: A tuple where the element denotes a condition value.\n",
        "    \"\"\"\n",
        "    print('\\nTotal number of incorrect labels:', len(incorrect_labels))\n",
        "    print('Incorrect labels are below: ')\n",
        "\n",
        "    for category in data_postprocessing['categories']:\n",
        "        if category['id'] in incorrect_labels:\n",
        "            name_parts = category['name'].split('_')\n",
        "\n",
        "            if m == 1 and len(name_parts) \u003e= 2:\n",
        "                print(f'{name_parts[0]}_{name_parts[1]}')\n",
        "            elif m == 4 and len(name_parts) \u003e= 5:\n",
        "                print(name_parts[4])\n",
        "    print('')\n",
        "\n",
        "\n",
        "def print_dict_characteristics(stage_num, dic):\n",
        "    \"\"\"Prints characteristics of the dictionary after post processing.\n",
        "\n",
        "    Args:\n",
        "        stage_num: The stage number of post processing.\n",
        "        data_postprocessing: The data containing postprocessing details.\n",
        "    \"\"\"\n",
        "    print(f'Dictionary characteristics after post processing stage {stage_num}:')\n",
        "    print('images:', len(dic['images']),\n",
        "          'categories:', len(dic['categories']),\n",
        "          'annotations:', len(dic['annotations']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG7OgYECSL2g"
      },
      "outputs": [],
      "source": [
        "LABELS = {\n",
        "'material_model' : 'two_model_strategy_material.csv',\n",
        "'material_form_model' : 'two_model_strategy_material_form.csv',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCyyokyRoydN"
      },
      "outputs": [],
      "source": [
        "# common labeling typo errors that have occured in the past data\n",
        "_KNOWN_TYPOS_IN_MATERIAL = {\n",
        "  '_PET_':'_PETE_',\n",
        "  'plastic_PP_':'_Plastics_PP_',\n",
        "  '_nothing_':'_Na_',\n",
        "  'plastic_MLP_':'Plastics_Others-MLP_',\n",
        "  'plastic_LDPE_':'Plastics_LDPE_',\n",
        "  'plastic_HDPE_':'Plastics_HDPE_',\n",
        "  'Metals_Aluminium_':'Metals_Na_',\n",
        "  'Plastics_PETEE_':'Plastics_PET_',\n",
        "  'Plastics_peTE_':'Plastics_PET_',\n",
        "  'Plastics_PETE_':'Plastics_PET_',\n",
        "}\n",
        "\n",
        "_KNOWN_TYPOS_IN_MATERIAL_FORM = {\n",
        "  'and': '\u0026',\n",
        "  '_Cassete_': '_Cassette_',\n",
        "  '_Toy_':'_Toys_',\n",
        "  '_Toyss_':'toys',\n",
        "  '_Cup-and-Glass_':'_Cup-\u0026-glass_',\n",
        "  '_Tanglers_':'_Tangler_',\n",
        "  '_tub_':'_Container_',\n",
        "  '_Jar_':'_Jug-\u0026-Jar_',\n",
        "  '_Mug-\u0026-Tub_':'_Container_',\n",
        "  '_nothing_':'_Na_',\n",
        "  '_Jugs_':'_Jug-\u0026-Jar_',\n",
        "  '_Cans_':'_Can_',\n",
        "  '_Bottlee_':'_Bottle_',\n",
        "  '_Tub_':'_Container_',\n",
        "  '_Flexiblesiii_':'_Flexibles_',\n",
        "  '_Paper-products-Whitepaper':'_Paper-Products-White-Paper_',\n",
        "  '_Paper-products-Other_':'_Paper-Products_',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-05VwsL0mCi"
      },
      "outputs": [],
      "source": [
        "# reading labels\n",
        "images_folder_path = 'image_folder/' #@param {type:\"string\"}\n",
        "\n",
        "category_indices, category_index = load_labels(LABELS)\n",
        "\n",
        "list_of_material = category_indices[0]\n",
        "list_of_material.remove('Na')\n",
        "\n",
        "list_of_material_form = category_indices[1]\n",
        "list_of_material_form.remove('Na')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZb1rvoWXKAr",
        "outputId": "d63cbf50-c3e4-4828-ebe9-242f78bbffd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Fiber_Na',\n",
              " 'Food_Na',\n",
              " 'Glass_Na',\n",
              " 'Inorganic-wastes_Na',\n",
              " 'Metals_Na',\n",
              " 'Plastics_HDPE',\n",
              " 'Plastics_LDPE',\n",
              " 'Plastics_Others-HIPC',\n",
              " 'Plastics_Others-MLP',\n",
              " 'Plastics_Others-Tetrapak',\n",
              " 'Plastics_PET',\n",
              " 'Plastics_PP',\n",
              " 'Plastics_PS',\n",
              " 'Plastics_PVC',\n",
              " 'Rubber-\u0026-Leather_Na',\n",
              " 'Textiles_Na',\n",
              " 'Wood_Na',\n",
              " 'Yard-trimming_Na']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display labels only for 'material' model\n",
        "list_of_material"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK-ae7HqXcn-",
        "outputId": "350620a2-ae3d-441c-9636-fea73ff6083e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Bag',\n",
              " 'Battery',\n",
              " 'Blister-pack',\n",
              " 'Book-\u0026-magazine',\n",
              " 'Bottle',\n",
              " 'Box',\n",
              " 'Brush',\n",
              " 'Bulb',\n",
              " 'Can',\n",
              " 'Cards',\n",
              " 'Carton',\n",
              " 'Cassette-\u0026-tape',\n",
              " 'Clamshell',\n",
              " 'Clothes',\n",
              " 'Container',\n",
              " 'Cosmetic',\n",
              " 'Cup-\u0026-glass',\n",
              " 'Cutlery',\n",
              " 'Electronic-devices',\n",
              " 'Flexibles',\n",
              " 'Foil',\n",
              " 'Foot-wear',\n",
              " 'Hangers',\n",
              " 'Jug-\u0026-Jar',\n",
              " 'Lid',\n",
              " 'Mirror',\n",
              " 'Office-Stationary',\n",
              " 'Paper-Products-Others',\n",
              " 'Paper-Products-Others-Cardboard',\n",
              " 'Paper-Products-Others-Newspaper',\n",
              " 'Paper-Products-Others-Whitepaper',\n",
              " 'Pipe',\n",
              " 'Sachets-\u0026-Pouch',\n",
              " 'Scissor',\n",
              " 'Tangler',\n",
              " 'Toys',\n",
              " 'Tray',\n",
              " 'Tube']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display labels only for 'material_form' model\n",
        "list_of_material_form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OoDmNC22ycz"
      },
      "source": [
        "## Find and delete truncated images from the image folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUUu3F6I20w3",
        "outputId": "a1ae3164-3f68-4745-bdee-23210113fd64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of files in the folder: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00\u003c00:00, 41.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "No broken images found\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "delete_truncated_images(images_folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65XuyPBSea7-"
      },
      "source": [
        "## Perform operations on the file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-uMtZK2edPY",
        "outputId": "771215ed-8950-419e-c7e8-380529f6beb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['images', 'annotations', 'categories'])\n"
          ]
        }
      ],
      "source": [
        "# read json file and it should contain at least the three keys as shown below\n",
        "path_to_json = 'dataset.json' #@param {type:\"string\"}\n",
        "data = read_json(path_to_json)\n",
        "print(data.keys())\n",
        "\n",
        "# create a copy to compare the results in the end\n",
        "data_preprocessing = copy.deepcopy(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8w7MfDtvDIq",
        "outputId": "6a48ea9d-084b-493a-e5ca-80c48fa5cbf7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:00\u003c00:00, 45590.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of wrong annotated labels are 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# checking labeling mistakes as all annotated labels should have 6 keywords connected by '_'\n",
        "num = 0\n",
        "for i in tqdm.tqdm(data['categories']):\n",
        "  if len(i['name'].split('_')) != 6:\n",
        "    num += 1\n",
        "print('\\nTotal number of wrong annotated labels are', num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2jOWegZxPEp",
        "outputId": "e988f4b0-e254-4fbe-80f3-99fe3a3504e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of labels which has less than 6 keywords are 0\n"
          ]
        }
      ],
      "source": [
        "# remove category labels which has less than 6 keywords\n",
        "categories = []\n",
        "num = 0\n",
        "for i in data['categories']:\n",
        "  if len(i['name'].split('_')) \u003e= 6:\n",
        "    categories.append(i)\n",
        "  else:\n",
        "    num += 1\n",
        "print('\\nTotal number of labels which has less than 6 keywords are', num)\n",
        "data['categories'] = categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qup_-ReIz-iv",
        "outputId": "13fae63a-e34f-4e1a-f071-475dfacf028f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:00\u003c00:00, 51463.85it/s]\n"
          ]
        }
      ],
      "source": [
        "# According to the collected data it was found that most issues occurs from the\n",
        "# 6th keyword which are the sub category of the material form.\n",
        "\n",
        "for i in tqdm.tqdm(data['categories']):\n",
        "  l1 = i['name'].split('_')[:5]\n",
        "  l2 = i['name'].split('_')[5:]\n",
        "  l1.append('-'.join(l2))\n",
        "  i['name'] = '_'.join(l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYqGTRluopxb",
        "outputId": "8fb71664-1bf1-41af-ae05-3b89492a0a44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:00\u003c00:00, 43464.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of wrong annotated labels are 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# checking labeling mistakes as all annotated labels should have 6 keywords connected by '_'\n",
        "num = 0\n",
        "for i in tqdm.tqdm(data['categories']):\n",
        "  if len(i['name'].split('_')) != 6:\n",
        "    num += 1\n",
        "print('\\nTotal number of wrong annotated labels are', num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfXv6qrTpDA-",
        "outputId": "111cf89b-6be4-4103-926a-9949fb235139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary characteristics before processing :\n",
            "images: 2 categories: 6 annotations: 6\n"
          ]
        }
      ],
      "source": [
        "print('Dictionary characteristics before processing :')\n",
        "print('images:',len(data_preprocessing['images']),'categories:', len(data_preprocessing['categories']),'annotations:',len(data_preprocessing['annotations']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro8KNGaGFv7k",
        "outputId": "05c388a4-942d-4620-d502-742e6cb989f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dictionary characteristics after post processing stage 1:\n",
            "images: 2 categories: 6 annotations: 6\n",
            "\n",
            "Total number of incorrect labels: 1\n",
            "Incorrect labels are below: \n",
            "Plastics_na\n",
            "\n",
            "Dictionary characteristics after post processing stage 2:\n",
            "images: 2 categories: 18 annotations: 6\n",
            "Dictionary characteristics after post processing stage 3:\n",
            "images: 2 categories: 18 annotations: 5\n",
            "Dictionary characteristics after post processing stage 4:\n",
            "images: 1 categories: 18 annotations: 5\n",
            "Dictionary characteristics after post processing stage 5:\n",
            "images: 1 categories: 18 annotations: 4\n",
            "\n",
            "Dictionary characteristics after processing of material_type_annotation :\n",
            "images: 1 categories: 18 annotations: 4\n",
            "###################################################################\n",
            "Dictionary characteristics after post processing stage 1:\n",
            "images: 2 categories: 6 annotations: 6\n",
            "\n",
            "Total number of incorrect labels: 0\n",
            "Incorrect labels are below: \n",
            "\n",
            "Dictionary characteristics after post processing stage 2:\n",
            "images: 2 categories: 38 annotations: 6\n",
            "Dictionary characteristics after post processing stage 3:\n",
            "images: 2 categories: 38 annotations: 6\n",
            "Dictionary characteristics after post processing stage 4:\n",
            "images: 1 categories: 38 annotations: 6\n",
            "Dictionary characteristics after post processing stage 5:\n",
            "images: 1 categories: 38 annotations: 5\n",
            "\n",
            "Dictionary characteristics after processing of material_form_type_annotation :\n",
            "images: 1 categories: 38 annotations: 5\n",
            "###################################################################\n"
          ]
        }
      ],
      "source": [
        "list_of_categories = [(list_of_material,1,'material_type_annotation.json',_KNOWN_TYPOS_IN_MATERIAL),\\\n",
        "                      (list_of_material_form,4,'material_form_type_annotation.json',_KNOWN_TYPOS_IN_MATERIAL_FORM)]\n",
        "\n",
        "for m in list_of_categories:\n",
        "\n",
        "  data_processing = copy.deepcopy(data)\n",
        "\n",
        "  objects_dictionaries = categories_dictionary(m[0])\n",
        "\n",
        "  # create a dict showing TDs corresponding to the labels \u0026 convert all words\n",
        "  # to lower case in order to eliminate case sensitive issues\n",
        "  labels_dict = dict([(i['id'], i['name'].lower()) for i in objects_dictionaries])\n",
        "\n",
        "  # correcting grammatical errors\n",
        "  data_processing = spelling_correction(data_processing, m[3])\n",
        "  print_dict_characteristics(1, data_processing)\n",
        "\n",
        "  # create a mapping table to map each label to the right label structure.\n",
        "  # find the incorrect labels.\n",
        "  mapping_dict, incorrect_labels = labeling_correction(data_processing, labels_dict, m[1])\n",
        "\n",
        "  print_incorrect_labels(incorrect_labels, data_processing, m[1])\n",
        "\n",
        "  # change the 'categories' key\n",
        "  data_processing['categories'] = objects_dictionaries\n",
        "  print_dict_characteristics(2, data_processing)\n",
        "\n",
        "  # change the 'annotation' key\n",
        "  data_processing['annotations'] = annotations_key(data_processing,  incorrect_labels, mapping_dict)\n",
        "  print_dict_characteristics(3, data_processing)\n",
        "\n",
        "  # change the 'images' key\n",
        "  data_processing['images'] = images_key(data_processing)\n",
        "\n",
        "  # remove data from the 'images' key not present in the image folder\n",
        "  data_processing = annotated_images(images_folder_path, data_processing)\n",
        "  print_dict_characteristics(4, data_processing)\n",
        "\n",
        "  # align 'images' and 'annotations' key\n",
        "  data_processing = image_annotation_key(data_processing)\n",
        "  print_dict_characteristics(5, data_processing)\n",
        "\n",
        "  # write to a new JSON file\n",
        "  with open(m[2], 'w') as opened_file:\n",
        "    opened_file.write(json.dumps(data_processing, indent=4))\n",
        "\n",
        "  print('\\nDictionary characteristics after processing of', m[2].replace('.json','') ,':')\n",
        "  print('images:',len(data_processing['images']),'categories:', len(data_processing['categories']),'annotations:',len(data_processing['annotations']))\n",
        "  print('###################################################################')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nC6XzQYL15Ki",
        "outputId": "ea8e0a7d-79bc-4321-8a63-4855afc190e1"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "      ((filepath) =\u003e {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/plastic_type_annotation.json\")"
            ],
            "text/plain": [
              "\u003cIPython.core.display.Javascript object\u003e"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# View the final JSON file\n",
        "try:\n",
        "  files.view(m[2]) # use files.download to download the file\n",
        "except ImportError:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7_PnincwKTE"
      },
      "source": [
        "# Visualization of categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty6WVqyywL61",
        "outputId": "df519b20-2776-4a3c-d22a-14becb58992d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-09-28 21:45:30--  https://raw.githubusercontent.com/tensorflow/models/master/official/projects/waste_identification_ml/pre_processing/config/visualization.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3268 (3.2K) [text/plain]\n",
            "Saving to: ‘visualization.py’\n",
            "\n",
            "\rvisualization.py      0%[                    ]       0  --.-KB/s               \rvisualization.py    100%[===================\u003e]   3.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-09-28 21:45:30 (24.5 MB/s) - ‘visualization.py’ saved [3268/3268]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download visualization script\n",
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/official/projects/waste_identification_ml/pre_processing/config/visualization.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKXJsmvgwPpA",
        "outputId": "884e658e-6e37-4ae1-9f28-18e03b55ba48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['material_type_annotation.json', 'material_form_type_annotation.json']\n"
          ]
        }
      ],
      "source": [
        "from visualization import visualize_detailed_counts_horizontally\n",
        "files = glob.glob('*annotation.json')\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjxwUBmOwdSe"
      },
      "outputs": [],
      "source": [
        "for file in files:\n",
        "  print(os.path.basename(file))\n",
        "  visualize_detailed_counts_horizontally(file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "JSON_Generation_for_Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
